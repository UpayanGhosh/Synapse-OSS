# ðŸ§¬ JARVIS â€” Multi-Agent AI Assistant with Hybrid Memory, Evolving Personality, and Privacy-First Routing

> A self-hosted AI system that remembers everything, develops its own personality 
> from conversation patterns, thinks before replying, and routes private conversations 
> to local models with zero cloud exposure. Built on top of 
> [OpenClaw](https://github.com/openclaw/openclaw). Running 24/7 on a MacBook Air.

> **New here?** Jump to [Quick Start](#-quick-start) or read [HOW_TO_RUN.md](HOW_TO_RUN.md) for full setup instructions.
>
> **Want the story behind the engineering?** Read [MANIFESTO.md](MANIFESTO.md) â€” the opinionated, in-character deep-dive.

![Python](https://img.shields.io/badge/Python-3.11-3776AB?style=for-the-badge&logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![SQLite](https://img.shields.io/badge/SQLite-003B57?style=for-the-badge&logo=sqlite&logoColor=white)
![Lines of Code](https://img.shields.io/badge/Lines_of_Code-15,000+-blueviolet?style=for-the-badge)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)
![Status](https://img.shields.io/badge/Status-Active-brightgreen?style=for-the-badge)

> **âš ï¸ CRITICAL: WhatsApp-Only Platform**
> This system is designed exclusively for **WhatsApp** messaging. All features â€” async message pipeline, persona routing, hybrid memory, The Vault privacy routing, and multi-model MoA â€” operate through WhatsApp webhooks and the WhatsApp API. Voice notes, media handling, and outbound messaging are all WhatsApp-specific.
> 
> **Coming Soon:** Support for Telegram, Discord, Slack, and other platforms is under active development and will be available in a future release. The architecture is designed to be platform-agnostic, so additional messaging channels will be added seamlessly once implemented.

---

## ðŸ’¡ What Makes This Different

Most AI chatbot projects are thin wrappers around an API call. 
JARVIS is an **11-subsystem architecture** that solves problems 
most chatbots ignore:

| Problem | How Most Bots Handle It | How JARVIS Handles It |
|---|---|---|
| **Memory** | Stuff messages into context window until it overflows | Hybrid RAG â€” SQLite knowledge graph + Qdrant vector search + FlashRank reranking. Remembers everything, retrieves what's relevant in <350ms. |
| **Personality** | Static system prompt, same tone forever | Soul-Brain Sync â€” continuously tracks mood, sentiment, language patterns. Rebuilds a behavioral profile every 50 messages. Personality evolves. |
| **Model selection** | One model for everything (expensive or dumb) | Mixture of Agents â€” Traffic Cop classifies intent, routes to 5 specialist models. Casual chat doesn't burn expensive API credits. |
| **Privacy** | Everything goes to cloud APIs | The Vault â€” sensitive conversations route to a local Ollama model on LAN. Zero cloud leakage. Zero external logging. |
| **Thinking** | Generate first token immediately | Dual Cognition â€” generates inner monologue, calculates tension between memory and current message, then responds. |
| **WhatsApp reliability** | Webhook timeout, lost messages, duplicates | Async pipeline â€” FloodGate batching, deduplication, bounded queue, concurrent workers. Zero dropped messages. |
| **RAM on consumer hardware** | "Just buy a bigger server" | Lazy-loading (ToxicScorer unloads after 30s idle), SQLite instead of NetworkX (99.2% memory reduction), thermal-aware workers. Runs on 8GB MacBook Air. |

---

## ðŸ“¸ Demo

### WhatsApp Conversation
> *JARVIS responding to a real message with memory context, persona adaptation, and model routing visible in the footer stats.*
> 
> *(Screenshots available in docs/ folder)*

### Architecture Overview
![Architecture Diagram](./architecture_diagram.svg)

---

## ðŸ“Š By The Numbers

> `99.2% memory reduction` Â· `<350ms P95 retrieval` Â· `6 models orchestrated` Â· `Zero dropped messages` Â· `24/7 uptime on $999 hardware` Â· `92 Python modules`

| Metric | Before (v1.0) | After (Phoenix v3) | Why it changed |
|---|---|:---:|---|
| Memory Footprint | ~155MB in-RAM graph (NetworkX) | **<1.2MB** | NetworkX required loading the entire graph into RAM, causing 81% memory pressure on an 8GB host. SQLite reads from disk on demand. **99.2% reduction.** |
| Host RAM Usage | 81.3% | **<25%** | Eliminated Qdrant container + NetworkX + separate memory server process into a single FastAPI app. **3.3Ã— lower.** |
| Retrieval Latency (P95) | ~1.2s | **<350ms** | High-confidence results (>0.80) bypass the reranker entirely â€” only ambiguous queries pay the FlashRank overhead. **3.4Ã— faster.** |
| Vocabulary Diversity | ~5,000 static terms | **37,868+** | Continuous ingestion from 4 years of conversation logs via the SBS batch pipeline. **7.6Ã— richer.** |
| Message Pipeline | Synchronous | **Async Queue** | Webhook returns `202 Accepted` immediately; processing happens in background workers. **Zero dropped messages** (single-user load). |
| Cognitive Overhead (TTFT) | N/A | **2-5s** | Dual Cognition pipeline adds 2-5s Time-To-First-Token for enhanced reasoning quality. **Quality-for-speed trade-off.** |

---

## ðŸ—ï¸ System Architecture

> *For the full interactive diagram with Mermaid breakdowns of each subsystem, see [ARCHITECTURE.md](ARCHITECTURE.md).*

The system consists of 11 interconnected subsystems:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        WhatsApp Webhook                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Async Gateway Pipeline                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚FloodGateâ”‚â†’â”‚ Dedup   â”‚â†’â”‚  Queue   â”‚â†’â”‚ MessageWorker â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Cognitive Pipeline                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Memory   â”‚â†’â”‚   SBS    â”‚â†’â”‚DualCognitionâ”‚â†’â”‚ TrafficCopâ”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Multi-Model Router                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Gemini â”‚ â”‚ Claude â”‚ â”‚ Ollama â”‚ â”‚  Vault â”‚ â”‚ Fallback â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸš€ Quick Start

```bash
# 1. Clone
git clone https://github.com/UpayanGhosh/Jarvis-OSS.git
cd Jarvis-OSS

# 2. Environment
python3 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# 3. Configure
cp .env.example .env
# Edit .env â€” add at minimum one LLM API key (GEMINI_API_KEY recommended)

# 4. Boot the Gateway
cd workspace/sci_fi_dashboard
python3 api_gateway.py
# Gateway starts on http://localhost:8000

# 5. Verify
curl http://localhost:8000/health
```

---

## ðŸ’» Usage Examples

### Chat with JARVIS

```bash
curl -X POST http://localhost:8000/chat/the_creator \
  -H "Content-Type: application/json" \
  -d '{"message": "What do you remember about our last conversation?"}'
```

### Query Memory

```bash
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"text": "What is the user\'s favorite programming language?"}'
```

### Add Memory

```bash
curl -X POST http://localhost:8000/add \
  -H "Content-Type: application/json" \
  -d '{"content": "The user prefers Python over JavaScript", "category": "tech_preferences"}'
```

### Check System Health

```bash
curl http://localhost:8000/health
```

### Rebuild Persona Profile

```bash
curl -X POST http://localhost:8000/persona/rebuild
```

> **Full setup guide** (Qdrant, Ollama, WhatsApp bridge, persona config): [HOW_TO_RUN.md](HOW_TO_RUN.md)
>
> **Persona customization** (how to make JARVIS yours): [SETUP_PERSONA.md](SETUP_PERSONA.md)

---

## âš™ï¸ Key Features

### Async Gateway Pipeline (Message Queue + Workers)
Messages enter through a multi-stage async pipeline (`gateway/`) that prevents webhook timeouts. A `FloodGate` (batch aggregator, 3s window) merges rapid-fire messages, a `MessageDeduplicator` (seen-set filter, 5-min window) absorbs retry storms, and a bounded `TaskQueue` (asyncio FIFO, max 100) feeds two concurrent `MessageWorker` instances. The webhook returns `202 Accepted` immediately â€” the cognitive pipeline processes in the background. **Zero dropped messages** under single-user load (~50-100 messages/day).

### Multi-Model Intent Router (Mixture of Agents Pattern)
A lightweight intent classifier (zero-shot Gemini Flash call) routes each message to the best-fit model: Gemini Flash for casual chat, Claude Sonnet for code generation, Gemini Pro for deep analysis, Claude Opus for critical review, or a local Ollama instance for private conversations. All models are accessed through a unified OpenAI-compatible proxy, making the system completely vendor-agnostic. A `CREDIT_SAVER` fallback gracefully downgrades to cheaper models when provider credits are exhausted.

### Hybrid Memory Retrieval (RAG)
The `MemoryEngine` combines a SQLite-backed knowledge graph (subjectâ€“predicateâ€“object triples) with Qdrant vector search (`nomic-embed-text` embeddings). A temporal scoring function blends semantic similarity with recency. High-confidence results (>0.80) skip the reranker for speed; lower-confidence candidates pass through FlashRank (ms-marco-TinyBERT) for precision. Result: **<350ms P95 retrieval** across 37,000+ vocabulary terms.

### Soul-Brain Sync (Continuous Batch Profiling Pipeline)
Rather than static system prompts, the SBS pipeline continuously builds and evolves a 2KB behavioral profile per conversation target. A `RealtimeProcessor` (rule-based sentiment + language detection) captures mood signals on every message. A `BatchProcessor` runs periodically (every 50 messages or 6 hours) to distill conversation patterns into structured JSON layers (emotional state, linguistic style, vocabulary). The `PromptCompiler` injects this profile into the system prompt at inference time. **Why not fine-tuning?** Profile injection is model-agnostic and costs zero training compute â€” the persona adapts regardless of which LLM is active.

### Dual Cognition Engine (Pre-Response Reasoning Layer)
Before generating a reply, a `DualCognitionEngine` produces an inner monologue (chain-of-thought via Gemini Flash) and calculates a tension score (0.0â€“1.0) to detect emotional conflicts between retrieved memory and the current message. This cognitive context is injected into the prompt alongside memories and persona. The `LazyToxicScorer` (Toxic-BERT) loads on demand and auto-unloads after 30s of idle to conserve RAM â€” on an 8GB machine, every MB matters.

### Air-Gapped Local Inference ("The Vault")
Sensitive conversations route to a local Ollama instance on a dedicated compute node (RTX 3060Ti). Zero cloud API calls, zero external logging. Hemisphere integrity (the separation between cloud-routed and local-only memories) is verified by automated tests (`verify` CLI command).

---

## ðŸŽ¯ Engineering Competencies Demonstrated

| **Competency**                   | **Evidence in This Repo**                                                                                                                                                                                      |
| :------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **System Design & Architecture** | Consolidated a 4-process architecture into a single FastAPI process, reducing memory from 155MB to <1.2MB (**99.2% reduction**). Motivated by 81% RAM pressure on an 8GB host â€” NetworkX loaded the full graph into RAM. |
| **Async Systems**                | Built an async queue-push message gateway with deduplication, flood batching, and concurrent workers â€” achieving **zero dropped messages** under single-user load (~50-100 msgs/day)                            |
| **Database Engineering**         | Designing a migration path from Qdrant to a native `sqlite-vec` implementation to eliminate container dependencies and further reduce RAM footprint (Currently supporting parallel retrieval paths).                 |
| **ML Pipeline Orchestration**    | Implemented a multi-model intent router (Mixture of Agents pattern) that classifies messages and dispatches to 6 models (Gemini, Claude, Ollama) through a unified OpenAI-compatible proxy                       |
| **Performance Optimization**     | Engineered lazy-loading patterns (Toxic-BERT loads on demand, unloads after 30s idle), `keep_alive: 0` model eviction, and thermal-aware background workers â€” all to run on a MacBook Air with 8GB RAM              |
| **Privacy Engineering**          | Designed air-gapped local inference routing with hemisphere-enforced memory separation, verified by automated integrity tests                                                                                        |
| **DevOps & Reliability**         | Built a `launchd`-managed boot sequence with idempotent service control, auto-restart, 12-hour backup rotation, and a real-time observability dashboard                                                            |
| **Continuous Batch Profiling**   | Built "Soul-Brain Sync" (SBS) â€” an autonomous ingestion â†’ parsing â†’ distillation pipeline that converts raw conversation logs into a 2KB behavioral profile, injected into the system prompt at inference time    |

---

## ðŸ› ï¸ Technical Stack

| **Category** | **Technologies**                                                                                               |
| :----------------- | :------------------------------------------------------------------------------------------------------------------- |
| Languages          | Python 3.11, JavaScript (Node.js), Bash                                                                              |
| Frameworks         | FastAPI, Uvicorn, OpenAI SDK                                                                                         |
| Databases          | SQLite (WAL Mode), `sqlite-vec`, Qdrant (Active)                                                                     |
| AI/ML              | Ollama, Google Gemini, Anthropic Claude, OpenRouter, Toxic-BERT, FlashRank, sentence-transformers, Whisper           |
| Infrastructure     | macOS `launchd`, OrbStack/Docker, distributed compute (remote GPU node)                                              |
| Practices          | Async programming, queue-based architectures, model-agnostic routing, automated testing, auto-commit version control |

---

## ðŸ¢ Functional Scope

> *This is a single-user, single-node system â€” not a distributed platform. But it covers a broad surface area of concerns typically split across multiple tools and teams:*
>
> **Async message processing** Â· **Multi-model intent routing** Â· **Hybrid knowledge retrieval** (vector + graph) Â· **Real-time log monitoring** Â· **Continuous behavioral profiling** Â· **Service lifecycle management**
>
> *Built and maintained by a single engineer on consumer hardware.*

---

## ðŸ“ Repository Layout

```
workspace/
â”œâ”€â”€ sci_fi_dashboard/              # Core application
â”‚   â”œâ”€â”€ api_gateway.py             #   Central FastAPI gateway (1,188 lines)
â”‚   â”œâ”€â”€ memory_engine.py           #   Hybrid RAG engine (Phoenix v3)
â”‚   â”œâ”€â”€ sqlite_graph.py            #   SQLite knowledge graph
â”‚   â”œâ”€â”€ dual_cognition.py          #   Inner monologue + tension engine
â”‚   â”œâ”€â”€ toxic_scorer_lazy.py       #   Lazy-loaded Toxic-BERT scorer
â”‚   â”œâ”€â”€ retriever.py               #   Qdrant + reranker utilities
â”‚   â”œâ”€â”€ conflict_resolver.py       #   Conflict detection & dedup
â”‚   â”œâ”€â”€ smart_entity.py            #   FlashText entity extraction
â”‚   â”œâ”€â”€ chat_parser.py             #   WhatsApp chat log parser
â”‚   â”œâ”€â”€ gateway/                   #   Async message pipeline
â”‚   â”‚   â”œâ”€â”€ queue.py               #     Bounded async task queue
â”‚   â”‚   â”œâ”€â”€ worker.py              #     Concurrent message workers
â”‚   â”‚   â”œâ”€â”€ sender.py              #     WhatsApp outbound via CLI
â”‚   â”‚   â”œâ”€â”€ dedup.py               #     Message deduplication
â”‚   â”‚   â””â”€â”€ flood.py               #     Batch window aggregator
â”‚   â””â”€â”€ sbs/                       #   Soul-Brain Sync persona engine
â”‚       â”œâ”€â”€ orchestrator.py        #     SBS lifecycle manager
â”‚       â”œâ”€â”€ ingestion/             #     Raw log â†’ JSONL pipeline
â”‚       â”œâ”€â”€ processing/            #     Realtime + batch analysis
â”‚       â”œâ”€â”€ injection/             #     Profile â†’ system prompt
â”‚       â”œâ”€â”€ profile/               #     Behavioral profile store
â”‚       â”œâ”€â”€ feedback/              #     Implicit feedback detection
â”‚       â””â”€â”€ sentinel/              #     File governance guardrails
â”œâ”€â”€ scripts/                       # Maintenance & utilities
â”‚   â”œâ”€â”€ revive_jarvis.sh           #   Full system resurrection
â”‚   â”œâ”€â”€ ram_watchdog.py            #   Memory pressure monitor
â”‚   â”œâ”€â”€ latency_watcher.py         #   Response time tracker
â”‚   â”œâ”€â”€ nightly_ingest.py          #   Scheduled memory digestion
â”‚   â”œâ”€â”€ fact_extractor.py          #   LLM â†’ knowledge triple extraction
â”‚   â””â”€â”€ transcribe_v2.py           #   Voice note â†’ text (Whisper)
â”œâ”€â”€ monitor.py                     # Real-time observability dashboard
â”œâ”€â”€ main.py                        # CLI interface (chat, verify, ingest, vacuum)
â””â”€â”€ change_tracker.py              # Auto git commit tracker
```

---

## ðŸ”Œ API Reference

| Method | Route | Description |
|---|---|---|
| `POST` | `/chat/the_creator` | Chat as primary user persona |
| `POST` | `/chat/the_partner` | Chat as partner persona |
| `POST` | `/chat` | Generic fallback chat |
| `POST` | `/whatsapp/enqueue` | Async WhatsApp message ingress |
| `GET`  | `/whatsapp/status/{id}` | Poll status of enqueued message |
| `POST` | `/persona/rebuild` | Rebuild persona profiles from logs |
| `GET`  | `/persona/status` | Profile statistics |
| `POST` | `/ingest` | Ingest structured fact into graph |
| `POST` | `/add` | Unstructured memory â†’ triple extraction |
| `POST` | `/query` | Query the knowledge graph |
| `GET`  | `/health` | System health check |
| `GET`  | `/v1/models` | OpenAI-compatible model list |
| `POST` | `/v1/chat/completions` | OpenAI-compatible chat proxy |

---

## ðŸ“ Engineering Philosophy

- **Architectural Decision-Making:** Every major subsystem was redesigned at least once based on production feedback â€” not theoretical planning.
- **Constraint-Driven Engineering:** The entire system was optimized to run on a $999 laptop with 8GB RAM. Every design choice was made under real resource pressure.
- **Production Mindset:** This isn't a demo. It processes real messages, from real users, every day. Uptime, latency, and reliability are measured, not aspirational.
- **End-to-End Ownership:** One engineer. Full stack. From SQLite schema design to async Python workers to shell-script orchestration to real-time monitoring dashboards.

---

## ðŸ‘¨â€ðŸ’» Built By

**Upayan Ghosh** â€” Fresher software engineer building AI systems on evenings and weekends.

This project was built using AI coding tools (Claude, ChatGPT,Gemini etc) 
for implementation, with architecture design, system integration, 
and debugging done by hand. I believe in using every tool available 
to build things that work.

- GitHub: [@UpayanGhosh](https://github.com/UpayanGhosh)
- LinkedIn: [https://linkedin.com/in/upayan](https://linkedin.com/in/upayan)
- Email: [upayan1231@gmail.com](mailto:upayan1231@gmail.com)

**Currently open to:** Freelance AI/chatbot projects, 
interesting collaborations, and conversations about RAG systems.

---

## ðŸ™ Attribution

> This entire project was built on the foundation of **[OpenClaw](https://github.com/openclaw/openclaw)**. OpenClaw provides the terminal instrumentation, browser automation, and multi-agent coordination system that made this "brain" possible. Deep respect and gratitude to the creators and maintainers of OpenClaw.

---

## ðŸ“š Documentation

| Document | Description |
|---|---|
| [ARCHITECTURE.md](ARCHITECTURE.md) | Full system architecture with Mermaid diagrams |
| [HOW_TO_RUN.md](HOW_TO_RUN.md) | Complete setup and deployment guide |
| [SETUP_PERSONA.md](SETUP_PERSONA.md) | Persona customization guide |
| [MANIFESTO.md](MANIFESTO.md) | The in-character design philosophy deep-dive |
| [CONTRIBUTING.md](CONTRIBUTING.md) | Contribution guidelines |
| [CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md) | Community code of conduct |
